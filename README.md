# pratica_ed
Pr√°tica de Engenharia de Dados

# üìä Desafio de Engenharia de Dados no Databricks


## 1 Ingest√£o de Dados
**Objetivo:** Armazenar os dados de forma estruturada na camada **Bronze**.

**O que foi feito:**
- Extra√ß√£o dos arquivos em parquet e salvos no modelo bronze no volume do databricks
- Aplicado apenas normaliza√ß√£o para colunas mapeadas que devem ter a mesma escrita em todas as bases, e caso n√£o exista fique nula.

**C√≥digo:**
ingest_parquet.py


## 2 Transforma√ß√£o e qualidade de Dados
**Objetivo:** Tratar, normalizar e limpar dados **Prata**.

**O que foi feito:**
- Identificado registros que n√£o contemplam as datas dos arquivos extraidos. pipckup e dropoff datetimes.
- Identificado registros com travel_distance fora do esperado quando analizado os datetimes e location da viagem.
- Campos de id como nome que modifiquei para valores padr√µes (nulos). RatecodeID, store_and_fwd_flag,payment_type.

**C√≥digo:**
transform_parquet.py


## 3 Vis√µes anal√≠ticas 
**Objetivo:** Criar metricas e indicadores **Ouro**.

**O que foi feito:**
- Indicadores a nivel diario, de pagamento e por hora, para an√°lise de custos de viagem, tempo de dura√ß√£o, media de passageiros e etc.

**C√≥digo:**
indicators_base.py


## 4 Automatiza√ß√£o 
**Objetivo:** Criar processo de carga continua.

**O que foi feito:**
- Script que chama as etapas bronze, prata e ouro, onde identifica se tem arquivo novo em raw data para processar.
- Leva em considera√ß√£o que um processo separado disponibiliza os arquivos no volume raw. N√£o foi possivel simular esse upload dos arquivos no volume do databricks e nem via request devido a limita√ß√µes da vers√£o community.

**C√≥digo:**
automatizacao_data_area.py


## 5 Infer√™ncia de informa√ß√µes 
**Objetivo:** Gerar insights relevantes sobre os dados tratatos.

**O que foi feito:**
- Evolu√ß√£o di√°ria (volume, receita, ticket) + m√©dia m√≥vel 7 dias
- Horarios do dia que mais tem corridas e receita
- Share de corridas e receita

**C√≥digo/:**
automatizacao_data_area.py
